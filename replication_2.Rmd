---
title: "Replication 2"
author: "Jack Luby"
date: "2/19/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r}
# Refresh global environment to re-run
rm(list = ls())
```

```{r}
###THE PACKAGES BELOW MAY NEED TO BE INSTALLED USING install.packages('x'), WHERE X IS THE PACKAGE NAME

library(dplyr)
library(ri)
library(RItools)
library(car)
library(xtable)
library(effects)
library(RColorBrewer)
library(kableExtra)
library(gt)
```

```{r}
options(scipen = 999)  ##set for non-scientific notation output

##Load data
dat.all = read.csv('dataverse_files/pnas_data.csv')
dat.t1 = read.csv('dataverse_files/t1_data.csv')
dat.all.prime = read.csv('dataverse_files/prime_data.csv')
###data loading for faces graphic
conf.dat = read.csv('dataverse_files/confederate_face_data.csv')
hisp.dat = read.csv('dataverse_files/hispanic_face_data.csv')
white.dat = read.csv('dataverse_files/white_face_data.csv')
```

```{r balance_check}
##balance_check.r
###check to see if randomization created balanced samples in Enos experiment
####RdE September 2012

out.balance.test = xBalance(fmla = treatment ~ liberal+republican+obama.disapprove+ride.everyday+voted.2010+romney.voter+Hispanics.x+age+residency.new+hispanic.new+college+income.new+male+white, data = dat.all, report = c("std.diffs","z.scores","adj.means","chisquare.test"), strata = factor(dat.all$station))
xtable.out.balance.text = xtable(out.balance.test) %>%
  select("treatment=0", 
         "treatment=1", 
         "std.diff", 
         "z") %>% 
  round(2) %>%
  add_row("treatment=0" = 117, "treatment=1" = 103, "std.diff" = "", "z"= "")

rownames(xtable.out.balance.text) <- c('Liberalⁱ', 'Republican', 'Obama disapprove', 'Ride MBTA every day', 'Voted 2010', 'Romney voter', 'Hispanic threat', 'Age', 'Residency year', 'Hispanic', 'College', 'Income', 'Male', 'White', "n")

xtable.out.balance.text %>% 
  gt(rownames_to_stub = T) %>% 
  cols_label("treatment=0" = "Control",
             "treatment=1" = "Treatment",
             "std.diff" = "Standard difference*",
             "z" = "Z score") %>% 
  tab_stubhead_label(label = "Condition") %>% 
  tab_header(title = md("*Table 2. Covariate balance across treatment conditions*")) %>%
  cols_align("right") %>% 
  tab_source_note("ⁱMean response values for pretreatment variables accounting for stratification into train stations. All variables are 0 and 1 variables, except for Hispanic threat, which is a seven-point scale indicating how threatening respondents find Hispanics, recoded 0-1; residency, which is measured in years; and income, which is annual income in dollars.") %>% 
  tab_source_note("*Difference in standardized units")

# missing.balance.test = xBalance(fmla = missing ~ liberal+republican+obama.disapprove+ride.everyday+voted.2010+romney.voter+Hispanics+age+residency.new+hispanic.new+gender+college+us.born+income.new+male, data = dat.t1, report = c("std.diffs","z.scores","adj.means","chisquare.test"),na.rm=T)
# print(missing.balance.test)

# missing.balance.test = xBalance(fmla = missing ~ numberim+Remain+Englishlan+liberal+republican+obama.disapprove+ride.everyday+voted.2010+romney.voter+Hispanics+age+residency.new+hispanic.new+gender+college+us.born+income.new+male, data = dat.t1, report = c("std.diffs","z.scores","adj.means","chisquare.test"),na.rm=T)
# print(missing.balance.test)

# missing.balance.test = xBalance(fmla = missing ~ treatment, data = dat.t1, report = c("std.diffs","z.scores","adj.means","chisquare.test"),na.rm=T)
# print(missing.balance.test)
```

```{r main_results}
##main_results.r
####primary randomization inferece

# Setting the variables over which we want to interate
repeats = c("numberim","Remain","Englishlan")

# Creating naming sets for the 'repeats', or questions, so that they can be used for separate calculations
x.names = paste(repeats,".x",sep="")
y.names = paste(repeats,".y",sep="")

# Setting the "covariates" concept for when we need to take them from dat.use. Currently called "line.x" in the dat.use table
covariates = c('line.x')

# Create an empty matrix to build on later
final.mat = matrix(nrow = 0, ncol = 8)

# Differentiate our subsets, "all" being everyone and "no.car" being only those who indicated they wait on the platform for the train (ie are likely to be more effected by the treatment effect).
subsets = c('all','no.car')

# Extranous declaration
cat('beginning inference \n')

# Iterate over "all" and then "no.car"
for(subset in subsets){

  # Create an out matrix with 8 variables, and one observation for each 'repeat', or question (length(repeats))
	out.mat = matrix(nrow = length(repeats), ncol = 8)
	
	# If we are not subsetting, we use all the data
	if(subset == 'all'){
		dat.subset = dat.all
	}
	# If we subset to only the platform waiters, we subset to only those whose 'habits' indicate that they wait on the platform 
	if(subset ==  'no.car'){
		dat.subset = dat.all[dat.all$habits != 1,]
		}

	# For whatever reason explicitly declare the word "treatment" for use later
	z.variable = 'treatment'
	
	# For each of the questions, we scale results from 0-1 by taking the actual data (responses ranging from 1-5), subtract 1, and divide by 4
	for(j in 1:length(repeats)){
	  # Rescale x to 0-4 then 0-1
		dat.subset$x.new = (as.numeric(dat.subset[,x.names[j]])-1)/4
		# Rescale y to 0-4 then 0-1
		dat.subset$y.new = (as.numeric(dat.subset[,y.names[j]])-1)/4  
		# Create "Y", the values we display in our table, by subtracting x.new from y.new
		dat.subset$Y = dat.subset$y.new - dat.subset$x.new
		
		# Take only the values that are not NA, for "use"
		dat.use = dat.subset[is.na(dat.subset$Y) == F,]
		
		# Calculate interest variables for each group
		x.sd = sd(dat.use$x.new,na.rm = T)
		x.mean = mean(dat.use$x.new,na.rm = T)
		y.mean = mean(dat.use$y.new,na.rm = T)
		y.treat = mean(dat.use$y.new[dat.use$treatment==1],na.rm = T)
	
		# Build a table of the stations which have no recorded control or no treatment observations so that they can be taken out (I think?)
		station.treatment.table = table(dat.use$station,dat.use[,z.variable])
		no.control.stations = names(which(station.treatment.table[,1] == 0))
		no.treatment.stations = names(which(station.treatment.table[,2] == 0))
		dat.use = dat.use[!dat.use$station%in%c(no.control.stations,no.treatment.stations),]
				
		
		dat.use$station = factor(dat.use$station)
		dat.use$treated_unit = factor(dat.use$treated_unit)
		# Take out the covariates (under "line.x") and save them as Xs
		Xs = data.matrix(dat.use[,covariates])
		
		# Generate perms and probabilities for establishing our ATE
		perms <- genperms(Z = dat.use[,z.variable], blockvar=dat.use$station, clustvar=dat.use$treated_unit)
		probs = genprobexact(Z = dat.use[,z.variable], blockvar=dat.use$station, clustvar=dat.use$treated_unit)

		# Generate variables of interest using the probabilities established above
		ate = estate(Y = dat.use$Y, Z = dat.use[,z.variable], X = Xs, prob = probs)
		Ys = genouts(Y = dat.use$Y, Z = dat.use[,z.variable], ate = 0)
		distout <- gendist(Ys,perms, prob=probs)
		disp =	dispdist(distout, ate = ate, display.plot = F)
		
		# Build an out table using all of the variables we have built above for each of the questions. End inner loop.
		out.mat[j,1] = repeats[j]
		out.mat[j,2] = subset
		out.mat[j,3] = nrow(dat.use)
		out.mat[j,4] = ate
		out.mat[j,5] = disp$greater.p.value
		out.mat[j,6] = disp$lesser.p.value
		out.mat[j,7] = x.sd
		out.mat[j,8] = x.mean
	}
	# Bind our results to our "final" mat which has both "all" and "no.car" treatments. End initial loop.
	final.mat = rbind(final.mat,out.mat)
	}

final.mat = as.data.frame(final.mat)
colnames(final.mat) = c('variable','subset','N','ate','greater.p.value','lesser.p.value','x.sd','x.mean')

final.mat.main = final.mat ##final.mat for output creation later

# Reproducing the table myself because I cannot be bothered to deal with all the nonsense below.
#output_create.r
# Taken from below and brought up to make the table we need

# Declare variables for use in table later
 output.vars = c('numberim','Remain','Englishlan')
 var.names = c('Number of immigrants be increased?ⁱ','Children of undocumented be allowed to stay?','English as official language?')

 
 ##Changed slightly because we don't need prime anymore
 final.mat.use = final.mat.main
 
 # Taking the values from final.mat.use and making them easier to use
 final.mat.use$greater.p.value = as.numeric(as.character(final.mat.use$greater.p.value)); final.mat.use$lesser.p.value = as.numeric(as.character(final.mat.use$lesser.p.value)); final.mat.use$ate = as.numeric(as.character(final.mat.use$ate)); final.mat.use$x.mean = as.numeric(as.character(final.mat.use$x.mean)); final.mat.use$x.sd = as.numeric(as.character(final.mat.use$x.sd)); final.mat.use$N = as.numeric(as.character(final.mat.use$N))
 final.mat.use$p.value = final.mat.use$greater.p.value

 # Create final.mat.redact by selecting out variables of interest, round numerics accordingly
 final.mat.redact = final.mat.use[,c('variable','subset','ate','p.value','x.mean','x.sd','N')]
 final.mat.redact[,c('ate','p.value','x.mean','x.sd')] = round(final.mat.redact[,c('ate','p.value','x.mean','x.sd')],3)

 # Create our new ate and mean outputs by integrating the p value, making it easier to use our table
 final.mat.redact$ate.new = paste(final.mat.redact$ate,' (',final.mat.redact$p.value,')',sep='')
 final.mat.redact$x.mean.new = paste(final.mat.redact$x.mean,' (',final.mat.redact$x.sd,')',sep='')

 # Create out.mat.a for just our "all" subset
 out.mat.a = final.mat.redact[final.mat.redact$subset == 'all'&final.mat.redact$variable %in% output.vars,]

 # Subset down our out.mats to just the values we need
 # Create N variables which are just the max values of our N's prior
 out.mat.a = final.mat.redact[final.mat.redact$subset == 'all'&final.mat.redact$variable %in% output.vars,c('ate.new')]	
 out.mat.c = final.mat.redact[final.mat.redact$subset == 'no.car'&final.mat.redact$variable %in% output.vars,c('ate.new')]
 out.mat.x = final.mat.redact[final.mat.redact$subset == 'all'&final.mat.redact$variable %in% output.vars,c('x.mean.new')]
 Ns = c('N',max(final.mat.redact$N[final.mat.redact$subset=='all']),
	max(final.mat.redact$N[final.mat.redact$subset=='no.car']),
	max(final.mat.redact$N[final.mat.redact$subset=='all'])
	)

 # Formatting
 hs = c('Question','ATE (p)*','CATE (p)','T1 levels (sd)')
 row.names(hs) = NULL
	
 # Bind all of our mat's together
 out.mat = cbind(out.mat.a,cbind(out.mat.c,out.mat.x))
 out.mat = cbind(var.names,out.mat)
 out.mat = rbind(out.mat,Ns)
 
 # Bind headings to our mat
 out.mat = rbind(hs,out.mat)
 
 # Create our out table, with necessary digits
 out.table = xtable(out.mat, digits = 3
	)

 out.table %>% 
   gt() %>% 
    cols_label("var.names" = "Question",
            "out.mat.a" = "All respondents",
            "out.mat.c" = "Waits on platform",
            "out.mat.x" = "All respondents") %>% 
   tab_header(title = md("*Table 1. Experiment results*")) %>% 
   tab_source_note("In the first 'All respondents' column, ATE represents responses in T2-T1 for the treatment group compared with the countrol group for the entire experimental sample. Positive values mean a more politically conservative response. In the 'Waits on platform' column, CATEs are the Conditional Average Treatment Effects fro persons who said they stand on the platform, rather than wait in their cars. In the second 'All respondents' column, T1 levels and SDs for each variable for all respondents. All variables scaled 0-1.") %>% 
   tab_source_note("*P values from a one-tailed test against the Null Hypothesis of no effect are in parentheses.") %>% 
   tab_source_note("ⁱEach of the questions allowed responses on a five-point scale ranging from strongly agree to strongly disagree (exact answers were changed to be appropriate to the actual question)")
   
   
   
```